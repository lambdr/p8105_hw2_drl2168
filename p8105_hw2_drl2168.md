P8105: Homework 2
================
Derek Lamb
2023-10-02

Load all relevant packages.

``` r
library(tidyverse)
library(readxl)
library(lubridate)
```

# Problem 1

### Politics data

I loaded in the dataframe and separated out the mon variable as
indicated. Because the prez_gop and prez_dem data were redundant, I
based the new president variable on prez_gop, then used `select` to
remove unneeded variables.

``` r
# Load in the data set and separate the mon variable into year, month, day

df_pol <- read_csv("data/pols-month.csv") |> 
  separate(mon, into = c("year", "month", "day"), "-") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year),
    president = case_match(
      prez_gop,
      2 ~ "gop",
      1 ~ "gop",
      0 ~ "dem"
    )) |> 
# Note the 2-coded prez_gop  

  select(-c(day, prez_dem, prez_gop))
```

### S&P 500 data

I read in `snp.csv` and went through the same cleaning steps. The date
was formatted differently, so I used `lubridate` to reformat it. I ended
up using `lubridate` more later, so I added it to the code chunk to load
packages. However, this assigned the incorrect year to everything before
1969, so I used `case_when` to reassign the year.

``` r
df_snp <- read_csv("data/snp.csv") |> 
  mutate(date = mdy(date)) |> 
  separate(date, into = c("year", "month", "day"), "-") |> 
  mutate(
    month = month.name[(as.numeric(month))],
    year = as.numeric(year),
    year = case_when(
      year > 2020 ~ year - 100,
      year < 2020 ~ year)
    ) |> 
  rename(snp_close = close) |> 
  select(-day) |> 
  arrange(year)
```

### Unemployment data

In working with the unemployment data, I decided to convert the
abbreviated months to full months by mapping from the built in vector
`month.abb` to another built in vector `month.name`. I had used
`month.name` above to go from month numbers to month names.

``` r
df_unemp <- read_csv("data/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(month = month.name[match(month, month.abb)]) |> 
  janitor::clean_names()
```

### Combining dataframes

Now I will merge these three dataframes into one dataframe.

``` r
# First, left_join political and s&p data
df_combined <- left_join(df_pol, df_snp, by = join_by(year, month))

# Next, add unemployment data
df_combined <- left_join(df_combined, df_unemp, by = join_by(year, month))
```

The `df_combined` dataframe is contains 822 rows of 11 variables. The
dataframe contains monthly records of U.S. political control at the
state and federal level, particularly whether the `president` was a
democrat or republican, the S&P 500 index (`snp_close`), and
unemployment rate (`unemployment`). The political data ranges from
1947-2015, although the S&P 500 and unemployment data only go back to
1950 and 1948, respectively, so the first 36 rows of the dataframe
contain missing data.

# Problem 2

### Mr. Trash Wheel

I already loaded `readxl`, so I will now import the Mr. Trash Wheel
data. The first row is an image, so I will skip that. There are two
extra columns that get read in, I think because of Excel’s formatting,
so I removed both of them. I made two additional changes to the data.
The `year` variable was a character variable, and so I converted it to a
numeric variable. I also fixed a typo that was in the date variable.

``` r
# Import and clean the Mr. Trash Wheel data
df_mr_tw <- read_excel("data/202207 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  rename(weight = weight_tons, volume = volume_cubic_yards) |> 
  select(-x15, -x16) |> 
  filter(dumpster != "") |> 
  mutate(homes_powered = weight*500/30) |> 
  mutate(wheel = "mr_trash_wheel",
         year = as.numeric(year)) |> 

# There is a typo in the 'date' variable of the data frame
# I decided to correct it here

  mutate(date = case_when(
    date == ymd("1900-01-20") ~ ymd("2020-01-20"),
    date != ymd("1900-01-20") ~ date))
```

### Professor Trash Wheel & Gwnnda the Trash Wheel

I then read in the Professor and Gwynnda Trash Wheel data, noting that
`df_prof_tw` does not have the variable `sports_balls` and that
`df_gwyn_tw` does not have the variables `glass_bottles`, `chip_bags`,
or `sports_balls`. While Mr. and Professor Trash Wheels contain the
variable `grocery_bags`, Gwynnda contains the variable `plastic_bag`. I
renamed this for consistency of variable names.

``` r
# Import and clean Prof. Trash Wheel data
df_prof_tw <- read_excel("data/202207 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  rename(weight = weight_tons, volume = volume_cubic_yards) |> 
  filter(dumpster != "") |> 
  mutate(homes_powered = weight*500/30) |> 
  mutate(wheel = "prof_trash_wheel")

# Import and clean Gwynnda Trash Wheel data
df_gwyn_tw <- read_excel("data/202207 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  rename(weight = weight_tons, 
         volume = volume_cubic_yards,
         grocery_bags = plastic_bags) |> 
  filter(dumpster != "") |> 
  mutate(homes_powered = weight*500/30) |> 
  mutate(wheel = "gwynnda_trash_wheel")
```

I then read in that `df_prof_tw` does not have the variable
`sports_balls` and that `df_gwyn_tw` does not have the variables
`glass_bottles`, `chip_bags`, or `sports_balls`.

### Combining Trash Wheel data

I will join the dataframes together using `bind_rows`.

``` r
df_tw <- bind_rows(df_mr_tw, df_prof_tw) |> 
  bind_rows(df_gwyn_tw) |> 
  select(-dumpster) |> 
  select(year, month, wheel, everything()) |> 
  arrange(date)
```

The `df_tw` dataframe contains 747 observations of 14 variables for 3
different trash wheels. On each `date`, the `weight` in tons and
`volume` in cubic yards of trash collected was recorded, as well as the
counts of certain common trash items, such as `cigarette_butts` or
`plastic_bottles`. This dataframe can be used to answer questions about
the performance of the different trash wheels. For example, Professor
Trash Wheel has collected a total of 190.12 tons of trash. Gwynnda the
Trash Wheel, which started operating in 2021, collected 16300 cigarette
butts in July of that year.

# Problem 3

### Baseline data

``` r
df_ad_bl <- read_csv("data/MCI_baseline.csv", 
                     skip = 1, 
                     na = ".") |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(sex,
      0 ~ "female",
      1 ~ "male"),
    apoe4 = case_match(apoe4, 
      0 ~ "non_carrier",
      1 ~ "carrier")
  ) |> 
  filter(age_at_onset > current_age | is.na(age_at_onset))
```

The first row was variable descriptions, so I skipped it in the import.
I additionally recoded the missing values from `.` to `NA`. I reassigned
`sex` and `apoe4` carrier status to a descriptive character value rather
than 0 or 1. Additionally, I removed any rows where the age at mild
cognitive impairment (MCI) onset preceded their baseline data being
recorded. There were 6 variables recorded in this dataframe, id,
demographic info, APOE4 carrier status, and age at MCI onset. In this
study, 479 eligible subjects were recruited, of which 93 developed MCI
during the course of the study. The average baseline age of participants
was 65 years old and 30% of the women in the study were carriers of the
APOE4 gene.

### Amyloid $\beta$ 42/40 data

``` r
df_amyloid <- read_csv("data/mci_amyloid.csv", 
                       skip = 1, 
                       na = c("Na", "NA")) |> 
  janitor::clean_names() |> 
  rename(id = study_id) |> 
  pivot_longer(baseline:time_8, 
               names_to = "time",
               values_to = "amyloid_ratio",
               names_prefix = "time_") |> 
  mutate(time = replace(time, time == "baseline", "0"),
         time = as.numeric(time),
         amyloid_ratio = as.numeric(amyloid_ratio))
```

I imported the data from `mci_amyloid.csv`. Missing values were coded as
either `NA` or `Na`; I corrected that in the `read_csv` function. I then
converted the data from a wide format to a long format, with the
variable `time` indicating when the measurement was taken and the
variable `amyloid_ratio` indicating the amyloid $\beta$ 42/40 ratio at
that given time.

### Combining baseline and amyloid data

To check whether there are differences in the subject id’s between the
two dataframes, I will count the number of IDs in `df_ad_bl`, the number
of unique IDs in `df_amyloid` - unique because there are repeats over
the `time` variable, and the number of items in the intersection of the
dataframes. If these numbers are not all equal, then there are different
subjects in the two dataframes.

``` r
# Baseline data
df_ad_bl |> 
  pull(id) |> 
  length()
```

    ## [1] 479

``` r
# Amyloid beta data
df_amyloid |> 
  pull(id) |> 
  unique() |> 
  length()
```

    ## [1] 487

``` r
# Overlap
length(intersect(pull(df_ad_bl, id), pull(df_amyloid, id)))
```

    ## [1] 471

These results show that there are 471 common subjects between the
dataframes, but 8 unique to `df_ad_bl` and 16 unique to `df_amyloid`. I
will combine the dataframes, but only include the 471 subjects who
appear in both dataframes.

``` r
df_ad <- inner_join(df_ad_bl, df_amyloid, by = join_by(id))
```

The final `df_ad` dataframe contains 2355 observations of 8 variables, 5
observations for each of the 471 subjects. It contains both their
demographic information and their amyloid $\beta$ 42/40 ratios over the
course of this longitudinal study. I will take the clean data set and
export it as `mci_study_clean.csv` and save it in the results folder.

``` r
write_csv(df_ad, "results/mci_study_clean.csv")
```
